{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## On the use of TF layers in the building of a Convolutional Neural Network\n",
    "#### *(draft)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overview\n",
    "A *convolutional neural network (CNN)* usually contains three component.\n",
    "\n",
    "1. a *convolutional layer* usually applies a certain amount of filter to the input. Each filter has a specific patch size and runs through image subregions. For each subregion, the layer perform a set of mathematical operations to produce a single value in the output **feature map**. Convolutional layers usually apply a *non-linear* function to introduce non-linearities into the model. In a standard convnet layer, a *ReLU* (rectified linear unit) function is used;\n",
    "2. a *pooling layer* usually downsamples the data extracted by the convolutional layer to reduce the dimensionality of the feature map and leading to a decreasing processing time. A common strategy is to use a *max pooling algorithm* which extracts subregions of the feature map. In short, a pooling layer takes a subregion of *n x m* size and keep a specific value, discarding all the others;\n",
    "3. A *dense* layer is a layer that comes after the *conv + pool* layers structure, which has all the neurons connected to each neuron (or *node*) in the previous layer.\n",
    "\n",
    "A typical CNN is made of a stack of convolutional modules that perform *feature extraction* and some dense fully-connected layer that performs *classification*. The final layer (called also *logits*) contains a neuron for each *target*, e.g. a label, with a *softmax* activation function in order to generate probability values between *0* and *1*, that is *how likely my input is described by each of my targets?*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# code skeleton\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# due import for cnn evaluation\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "# set threshold for logging output produced\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CNN structure\n",
    "\n",
    "##### - convolutional modules -\n",
    "- conv layer #1: applies 256 filters which span subregion of 128x6 with ReLU activation function\n",
    "- pool layer #1: performs a max pooling with a 128x4 filter and stride of 4 (not overlapped)\n",
    "- conv layer #2: applies 256 filters which span subregion of 256x6 with ReLU activation function\n",
    "- pool layer #2: performs a max pooling with a 256x4 filter and stride of 2 (overlapped)\n",
    "- conv layer #3: applies 512 filters which span subregion of 256x6 with ReLU activation function\n",
    "- pool layer #3: performs a max pooling with a 512x4 filter and stride of 2 (overlapped) \n",
    "\n",
    "##### - dense modules - \n",
    "- dense layer #1: 2048 neurons\n",
    "- dense layer #2: 2048 neurons with dropout regolarisation\n",
    "- dense layer #3: readout layer (logits) with as many neurons as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 862, 128)\n"
     ]
    }
   ],
   "source": [
    "# A. prepare the input\n",
    "#Â (3D-tensor input required for 1D convolution, e.g. temporal convolution)\n",
    "batch_size = 3 # an example\n",
    "\n",
    "# - to check\n",
    "# input length: 10-sec long spectrogram = 862 timesteps\n",
    "# input dimension: mel-spectrogram bins = 128\n",
    "input_layer = tf.placeholder(tf.float32, [batch_size, 862, 128])\n",
    "\n",
    "# dimensions check\n",
    "print(input_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 862, 256)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c48912c4d421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# get activation values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "# B. Convolutional layer #1\n",
    "# This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "# obs: kernel size has only one value since the convolution is only temporal\n",
    "conv1 = tf.layers.conv1d(\n",
    "    inputs=input_layer, \n",
    "    filters=256, \n",
    "    kernel_size=[6], # the filter is spanning 6 timesteps\n",
    "    padding=\"same\", \n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# dimensions check\n",
    "print(conv1.shape)\n",
    "\n",
    "# get activation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 216, 256)\n"
     ]
    }
   ],
   "source": [
    "# C. Pooling layer #1\n",
    "pool1 = tf.layers.max_pooling1d(\n",
    "    inputs=conv1, \n",
    "    pool_size=4, \n",
    "    strides=4, # none of the subregions will overlap\n",
    "    padding=\"same\"\n",
    ")\n",
    "\n",
    "# dimensions check - expected reduced length by 75%\n",
    "print(pool1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 216, 256)\n",
      "(3, 108, 256)\n"
     ]
    }
   ],
   "source": [
    "# D. Convolutional + pooling layer #2\n",
    "conv2 = tf.layers.conv1d(\n",
    "    inputs=pool1, \n",
    "    filters=256, \n",
    "    kernel_size=[6], # the filter is spanning 6 timesteps\n",
    "    padding=\"same\", \n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# dimensions check\n",
    "print(conv2.shape)\n",
    "\n",
    "\n",
    "pool2 = tf.layers.max_pooling1d(\n",
    "    inputs=conv2, \n",
    "    pool_size=2, \n",
    "    strides=2, # none of the subregions will overlap\n",
    "    padding=\"same\"\n",
    ")\n",
    "\n",
    "# dimensions check - expected reduced length by 50%\n",
    "print(pool2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 108, 512)\n"
     ]
    }
   ],
   "source": [
    "# D. Convolutional layer #3\n",
    "conv3 = tf.layers.conv1d(\n",
    "    inputs=pool2, \n",
    "    filters=512, \n",
    "    kernel_size=[6], # the filter is spanning 6 timesteps\n",
    "    padding=\"same\", \n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# dimensions check\n",
    "print(conv3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 512)\n",
      "(3, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "# E. Global temporal pooling \n",
    "# It pools across the entire time axis, i.e. one value per filter\n",
    "\n",
    "# using max pooling \n",
    "pool3Max = tf.layers.max_pooling1d(\n",
    "    inputs=conv3, \n",
    "    pool_size=108, \n",
    "    strides=108,\n",
    "    padding=\"same\"\n",
    ")\n",
    "\n",
    "# using average pooling\n",
    "pool3Avg = tf.layers.average_pooling1d(\n",
    "    inputs=conv3,\n",
    "    pool_size=108,\n",
    "    strides=108,\n",
    "    padding=\"same\"\n",
    ")\n",
    "\n",
    "\n",
    "# dimensions check - expected same for both tensors\n",
    "print(pool3Max.shape)\n",
    "print(pool3Avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 512)\n",
      "(3, 1024)\n"
     ]
    }
   ],
   "source": [
    "# stack the two pooling layers\n",
    "globalPool = tf.concat([pool3Max,pool3Avg], axis=1)\n",
    "print(globalPool.shape)\n",
    "\n",
    "# reshape in tensor like [batch_size, features]\n",
    "pool_flat = tf.reshape(globalPool,[-1, 2*512])\n",
    "print(pool_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2048)\n",
      "(3, 2048)\n"
     ]
    }
   ],
   "source": [
    "# F. Dense layers\n",
    "# They are mainly used to perform classification on the features extracted by the convolutional module.\n",
    "\n",
    "# functional interface for densely-connected layers\n",
    "# (implements the operation: outputs = activation(inputs.kernel + bias))\n",
    "# dense layer #1\n",
    "dense1 = tf.layers.dense(\n",
    "    inputs=pool_flat,\n",
    "    units=2048,\n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# dense layer #2\n",
    "dense2 = tf.layers.dense(\n",
    "    inputs=dense1,\n",
    "    units=2048,\n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# dropout regularisation for dense layer #2\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense2,\n",
    "    rate=0.5, # 50% elements randomly dropped out during training\n",
    "    training=True\n",
    ")\n",
    "\n",
    "# dimensions check\n",
    "print(dense1.shape)\n",
    "print(dense2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "# G. logits layer\n",
    "# units number chosen by heuristics (to be changed?)\n",
    "logits = tf.layers.dense(\n",
    "    activation=tf.nn.softmax,\n",
    "    inputs=dense2,\n",
    "    units=10\n",
    ")\n",
    "\n",
    "# dimensions check\n",
    "print(logits.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
